{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd8e96a2-8985-49c4-963a-e76d71eb39f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelalves/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "import os\n",
    "import config\n",
    "\n",
    "llm = Groq(model=\"llama3-70b-8192\", api_key=config.apiToken())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47a7976-d9e2-4a1d-a005-036a510e5136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19783cb4503842ceb8e1b1ac8139527b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395bdf3f5d3e40a5896f255abc400fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bad49d29b65421e9f113b6bfe42b862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/114k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee08761bacf45c5842789d452462065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28239ce55784e60a4a76db8b5b67907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9619fa3e91d48279fd144fb060923f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d29377a92b47539cf8984f006c8dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd471cd8f3e4575990274068bc42296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cca98323e142a08bd08274a26c8bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110a039ddb67492b8cf1d27a341d7167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6588e37451734ff8be271d9847cfbdc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34684e2e-81d7-4671-a3e4-1aa8b37136d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf39282-e30c-4b7b-bb27-4d918e60ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "de_tools_blog = SimpleDirectoryReader(\"./\",required_exts=[\".pdf\", \".docx\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ba2a33-e8ba-4d4e-8f91-8af01f3c300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_documents(de_tools_blog)\n",
    "query_engine = index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "response = query_engine.query(\"How many tools are there?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4416a2-f3d9-4bde-be92-4565e685ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the document, the following tools are suitable for data processing:\n",
      "\n",
      "1. Apache Spark: A powerful open-source distributed computing framework designed for large-scale data processing and analysis. It excels in batch processing and is highly scalable and fast, making it ideal for batch processing in data engineering tasks.\n",
      "\n",
      "2. Apache Hadoop: A popular open-source framework for distributed storage and processing of large datasets. It offers cost-effective storage, fault tolerance, distributed processing capabilities, and seamless integration with other data processing tools.\n",
      "\n",
      "3. Apache Kafka: A distributed event streaming platform designed for high-performance, real-time data processing and streamlining of large-scale data pipelines. It can handle a large amount of data with low latency and stores data in a distributed and fault-tolerant manner.\n",
      "\n",
      "4. Apache Flink: An open-source platform for distributed stream and batch processing. It can process data streams in real-time, making it a popular choice for building streaming data pipelines and real-time analytics applications. It provides fast and efficient real-time and batch data processing capabilities.\n",
      "\n",
      "These tools are mentioned in the document as essential data engineering tools for data processing, and they are suitable for different types of data processing tasks, including batch processing, real-time data processing, and stream processing.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.core.chat_engine import CondensePlusContextChatEngine\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=3900)\n",
    "\n",
    "chat_engine = CondensePlusContextChatEngine.from_defaults(    \n",
    "   index.as_retriever(),    \n",
    "   memory=memory,    \n",
    "   llm=llm\n",
    ")\n",
    "\n",
    "response = chat_engine.chat(    \n",
    "   \"What tools are suitable for data processing?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b78955-343f-4986-adad-80236e611600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a possible diagram of a data pipeline using the tools mentioned:\n",
      "\n",
      "```\n",
      "                                      +---------------+\n",
      "                                      |  Data Source  |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  Apache Kafka  |\n",
      "                                      |  (Event Streaming) |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  Apache Flink  |\n",
      "                                      |  (Real-time Processing) |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  Apache Spark  |\n",
      "                                      |  (Batch Processing)  |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  Apache Hadoop  |\n",
      "                                      |  (Distributed Storage) |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  Data Warehouse  |\n",
      "                                      |  (Snowflake or PostgreSQL) |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  dbt (Data Transformation) |\n",
      "                                      +---------------+\n",
      "                                             |\n",
      "                                             |\n",
      "                                             v\n",
      "                                      +---------------+\n",
      "                                      |  Metabase (Analytics) |\n",
      "                                      +---------------+\n",
      "```\n",
      "\n",
      "This diagram shows a data pipeline that starts with a data source, which sends events to Apache Kafka for real-time processing. Apache Flink can then process these events in real-time, and Apache Spark can process the data in batches. The processed data is then stored in Apache Hadoop for distributed storage. The data is then loaded into a data warehouse, such as Snowflake or PostgreSQL, for querying and analysis. The data is then transformed using dbt, and finally, it is used for analytics and reporting with Metabase.\n",
      "\n",
      "Please note that this is just one possible way to design a data pipeline using these tools, and the actual architecture may vary depending on the specific use case and requirements.\n"
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\n",
    "    \"Can you create a diagram of a data pipeline using these tools?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179118d4-23ef-45ad-acff-fba36a7eb63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
